{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation notebook\n",
    "\n",
    "<ol>\n",
    "<li> uses the half hourly data </li> \n",
    "<li> sorts each block of the  dataset by time and fills forward the hourly weather data </li>\n",
    "<li> converts time stamp columns minute of day,  day of week, month etc </li>      \n",
    "<li> converts categorical columns to ints  (not one hot encoded ).  The mapping is persisted in nested dictionary called `cat_map.pkl`</li>   \n",
    "<li> each block file after being processes with the above feature engineering is appended to a bcolz array </li>     \n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import bcolz\n",
    "import shutil\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = 'energy(kWh/hh)'\n",
    "categorical_cols = ['LCLid', 'stdorToU', 'Acorn_grouped', 'Acorn', 'summary', 'h_summary', 'icon', 'h_icon', 'h_precipType']\n",
    "numeric_cols = ['h_visibility','h_windBearing','h_temperature','h_dewPoint','h_pressure','h_apparentTemperature'\n",
    ",'h_windSpeed','h_humidity','month_x','dayofweek','isHoliday','halfhourofday','temperatureMax'\n",
    ",'windBearing','dewPoint','cloudCover','windSpeed','pressure','apparentTemperatureHigh','visibility','humidity','apparentTemperatureLow'\n",
    ",'apparentTemperatureMax','uvIndex','temperatureLow','temperatureMin','temperatureHigh','apparentTemperatureMin'\n",
    ",'moonPhase','temperatureMinTime_mod','temperatureMaxTime_mod','apparentTemperatureMinTime_mod','apparentTemperatureMaxTime_mod'\n",
    ",'temperatureHighTime_mod','temperatureLowTime_mod','apparentTemperatureHighTime_mod','apparentTemperatureLowTime_mod'\n",
    ",'sunsetTime_mod','sunriseTime_mod','uvIndexTime_mod']\n",
    "allcols = np.concatenate([categorical_cols ,  numeric_cols ]).tolist()\n",
    "allcols.append(label_col)\n",
    "cat_map= dict()\n",
    "for c in categorical_cols:\n",
    "    cat_map[c]=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvalue_for_column(colname,value):\n",
    "    global cat_map\n",
    "    if not value in cat_map[colname].keys():\n",
    "        td = cat_map[colname]\n",
    "        cnt = len(td.values())\n",
    "        td[value]=cnt+1\n",
    "        cat_map[colname]=td\n",
    "    return cat_map[colname][value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_hour_of_day(datestring, formatstr='%Y-%m-%d %H:%M:%S.%f', stripChars=6):\n",
    "    if stripChars>0:\n",
    "        tmp = datetime.strptime(datestring[:-stripChars], formatstr)\n",
    "    else:\n",
    "        tmp = datetime.strptime(datestring, formatstr)\n",
    "    return 2*(tmp.hour + (tmp.minute /60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minute_of_day(datestring, formatstr='%Y-%m-%d %H:%M:%S.%f', stripChars=6):\n",
    "    if type(datestring)==float:\n",
    "        return np.nan\n",
    "    if stripChars>0:\n",
    "        tmp = datetime.strptime(datestring[:-stripChars], formatstr)\n",
    "    else:\n",
    "        tmp = datetime.strptime(datestring, formatstr)\n",
    "    return ((tmp.hour*60) + tmp.minute )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts_int(datestring, formatstr='%Y-%m-%d %H:%M:%S.%f', stripChars=6):\n",
    "    if type(datestring)==float:\n",
    "        return np.nan\n",
    "    if stripChars>0:\n",
    "        tmp = datetime.strptime(datestring[:-stripChars], formatstr)\n",
    "    else:\n",
    "        tmp = datetime.strptime(datestring, formatstr)\n",
    "    start = datetime(2000,1, 1 )\n",
    "    delta = tmp-start\n",
    "    return delta.days*24*3600 + delta.seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time_cols(data_frame, column_name):\n",
    "    data_frame[column_name+ \"_mod\"] = data_frame[column_name].apply(lambda x: minute_of_day(x, formatstr='%Y-%m-%d %H:%M:%S', stripChars=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"data\"\n",
    "BLOCK_PATH = os.path.join(DATA_ROOT,'halfhourly_dataset') \n",
    "BLOCKS = os.listdir(BLOCK_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist_bcolz(chunk_number, data, processed_data_dir):\n",
    "    global da\n",
    "    if chunk_number == 0:\n",
    "        if os.path.isdir(processed_data_dir):\n",
    "            shutil.rmtree(processed_data_dir)\n",
    "        da = bcolz.carray(data, rootdir=processed_data_dir)\n",
    "        #da.flush()\n",
    "    else: \n",
    "        #da = bcolz.open(rootdir=processed_data_dir, mode='w')\n",
    "        da.append(data)\n",
    "        #da.flush()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_weather = pd.read_csv(os.path.join(DATA_ROOT, \"weather_hourly_darksky.csv\"))\n",
    "daily_weather  = pd.read_csv(os.path.join(DATA_ROOT, \"weather_daily_darksky.csv\"))\n",
    "house          = pd.read_csv(os.path.join(DATA_ROOT, \"informations_households.csv\"))\n",
    "holidays       = pd.read_csv(os.path.join(DATA_ROOT, \"uk_bank_holidays.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_weather.columns = [\"h_\"+ c for c in hourly_weather.columns]\n",
    "hourly_weather.rename(columns={\"h_time\":\"time\"}, inplace=True)\n",
    "hols = holidays['Bank holidays'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_weather['month']=[ int(v[5:7]) for v in daily_weather['time'].values]\n",
    "for c in ['temperatureMinTime', 'temperatureMaxTime', 'apparentTemperatureMinTime','apparentTemperatureMaxTime','temperatureHighTime','temperatureLowTime','apparentTemperatureHighTime','apparentTemperatureLowTime','sunsetTime','sunriseTime','uvIndexTime']:\n",
    "    convert_time_cols(daily_weather, c)\n",
    "daily_weather['date']=[ v[:10] for v in daily_weather['temperatureMinTime'].values]  \n",
    "daily_weather.fillna(method='ffill', inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## per block operations\n",
    "def feature_eng(df):\n",
    "    df['time']=  df['tstp'].astype(str).str[:19]\n",
    "    df = pd.merge(df, house, on='LCLid', how='left')\n",
    "    df = pd.merge(df, hourly_weather, on='time',  how='left')\n",
    "    df['month']=[ int(v[5:7]) for v in df['tstp'].values]\n",
    "    df['dayofweek']=[datetime.strptime(v[:-6], '%Y-%m-%d %H:%M:%S.%f').weekday()  for v in df['tstp'].values]\n",
    "    df['isHoliday']=[v[:10] in hols  for v in df['tstp'].values]\n",
    "    df['halfhourofday'] = df.tstp.apply(lambda x: half_hour_of_day(x) )\n",
    "    df['date']=[ v[:10] for v in df['tstp'].values] \n",
    "    df['ts_int'] = df.tstp.apply(lambda x: get_ts_int(x))\n",
    "    df = pd.merge(df, daily_weather, on='date', how='left')\n",
    "    df.sort_values(by='ts_int', ascending=True, inplace=True)\n",
    "    hcols =['h_visibility', 'h_windBearing', 'h_temperature','h_dewPoint', 'h_pressure', 'h_apparentTemperature', 'h_windSpeed',\n",
    "       'h_precipType', 'h_icon', 'h_humidity', 'h_summary']\n",
    "    df[hcols]= df[hcols].ffill()\n",
    "    df[label_col] = pd.to_numeric(df[label_col], errors='coerce')\n",
    "    for c in categorical_cols:  # convert cat columns to ints\n",
    "        df[c] = df[c].apply(lambda x: getvalue_for_column(c,x))\n",
    "    return df[allcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting  block  0\n",
      "completed block  0\n",
      "starting  block  1\n",
      "completed block  1\n",
      "starting  block  2\n",
      "completed block  2\n",
      "starting  block  3\n",
      "completed block  3\n",
      "starting  block  4\n",
      "completed block  4\n",
      "starting  block  5\n",
      "completed block  5\n",
      "starting  block  6\n",
      "completed block  6\n",
      "starting  block  7\n",
      "completed block  7\n",
      "starting  block  8\n",
      "completed block  8\n",
      "starting  block  9\n",
      "completed block  9\n",
      "starting  block  10\n",
      "completed block  10\n",
      "starting  block  11\n",
      "completed block  11\n",
      "starting  block  12\n",
      "completed block  12\n",
      "starting  block  13\n",
      "completed block  13\n",
      "starting  block  14\n",
      "completed block  14\n",
      "starting  block  15\n",
      "completed block  15\n",
      "starting  block  16\n",
      "completed block  16\n",
      "starting  block  17\n",
      "completed block  17\n",
      "starting  block  18\n",
      "completed block  18\n",
      "starting  block  19\n",
      "completed block  19\n",
      "starting  block  20\n",
      "completed block  20\n",
      "starting  block  21\n",
      "completed block  21\n",
      "starting  block  22\n",
      "completed block  22\n",
      "starting  block  23\n",
      "completed block  23\n",
      "starting  block  24\n",
      "completed block  24\n",
      "starting  block  25\n",
      "completed block  25\n",
      "starting  block  26\n",
      "completed block  26\n",
      "starting  block  27\n",
      "completed block  27\n",
      "starting  block  28\n",
      "completed block  28\n",
      "starting  block  29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed block  29\n",
      "starting  block  30\n",
      "completed block  30\n",
      "starting  block  31\n",
      "completed block  31\n",
      "starting  block  32\n",
      "completed block  32\n",
      "starting  block  33\n",
      "completed block  33\n",
      "starting  block  34\n",
      "completed block  34\n",
      "starting  block  35\n",
      "completed block  35\n",
      "starting  block  36\n",
      "completed block  36\n",
      "starting  block  37\n",
      "completed block  37\n",
      "starting  block  38\n",
      "completed block  38\n",
      "starting  block  39\n",
      "completed block  39\n",
      "starting  block  40\n",
      "completed block  40\n",
      "starting  block  41\n",
      "completed block  41\n",
      "starting  block  42\n",
      "completed block  42\n",
      "starting  block  43\n",
      "completed block  43\n",
      "starting  block  44\n",
      "completed block  44\n",
      "starting  block  45\n",
      "completed block  45\n",
      "starting  block  46\n",
      "completed block  46\n",
      "starting  block  47\n",
      "completed block  47\n",
      "starting  block  48\n",
      "completed block  48\n",
      "starting  block  49\n",
      "completed block  49\n",
      "starting  block  50\n",
      "completed block  50\n",
      "starting  block  51\n",
      "completed block  51\n",
      "starting  block  52\n",
      "completed block  52\n",
      "starting  block  53\n",
      "completed block  53\n",
      "starting  block  54\n",
      "completed block  54\n",
      "starting  block  55\n",
      "completed block  55\n",
      "starting  block  56\n",
      "completed block  56\n",
      "starting  block  57\n",
      "completed block  57\n",
      "starting  block  58\n",
      "completed block  58\n",
      "starting  block  59\n",
      "completed block  59\n",
      "starting  block  60\n",
      "completed block  60\n",
      "starting  block  61\n",
      "completed block  61\n",
      "starting  block  62\n",
      "completed block  62\n",
      "starting  block  63\n",
      "completed block  63\n",
      "starting  block  64\n",
      "completed block  64\n",
      "starting  block  65\n",
      "completed block  65\n",
      "starting  block  66\n",
      "completed block  66\n",
      "starting  block  67\n",
      "completed block  67\n",
      "starting  block  68\n",
      "completed block  68\n",
      "starting  block  69\n",
      "completed block  69\n",
      "starting  block  70\n",
      "completed block  70\n",
      "starting  block  71\n",
      "completed block  71\n",
      "starting  block  72\n",
      "completed block  72\n",
      "starting  block  73\n",
      "completed block  73\n",
      "starting  block  74\n",
      "completed block  74\n",
      "starting  block  75\n",
      "completed block  75\n",
      "starting  block  76\n",
      "completed block  76\n",
      "starting  block  77\n",
      "completed block  77\n",
      "starting  block  78\n",
      "completed block  78\n",
      "starting  block  79\n",
      "completed block  79\n",
      "starting  block  80\n",
      "completed block  80\n",
      "starting  block  81\n",
      "completed block  81\n",
      "starting  block  82\n",
      "completed block  82\n",
      "starting  block  83\n",
      "completed block  83\n",
      "starting  block  84\n",
      "completed block  84\n",
      "starting  block  85\n",
      "completed block  85\n",
      "starting  block  86\n",
      "completed block  86\n",
      "starting  block  87\n",
      "completed block  87\n",
      "starting  block  88\n",
      "completed block  88\n",
      "starting  block  89\n",
      "completed block  89\n",
      "starting  block  90\n",
      "completed block  90\n",
      "starting  block  91\n",
      "completed block  91\n",
      "starting  block  92\n",
      "completed block  92\n",
      "starting  block  93\n",
      "completed block  93\n",
      "starting  block  94\n",
      "completed block  94\n",
      "starting  block  95\n",
      "completed block  95\n",
      "starting  block  96\n",
      "completed block  96\n",
      "starting  block  97\n",
      "completed block  97\n",
      "starting  block  98\n",
      "completed block  98\n",
      "starting  block  99\n",
      "completed block  99\n",
      "starting  block  100\n",
      "completed block  100\n",
      "starting  block  101\n",
      "completed block  101\n",
      "starting  block  102\n",
      "completed block  102\n",
      "starting  block  103\n",
      "completed block  103\n",
      "starting  block  104\n",
      "completed block  104\n",
      "starting  block  105\n",
      "completed block  105\n",
      "starting  block  106\n",
      "completed block  106\n",
      "starting  block  107\n",
      "completed block  107\n",
      "starting  block  108\n",
      "completed block  108\n",
      "starting  block  109\n",
      "completed block  109\n",
      "starting  block  110\n",
      "completed block  110\n",
      "starting  block  111\n",
      "completed block  111\n"
     ]
    }
   ],
   "source": [
    "for i, block in enumerate (BLOCKS):\n",
    "    print (\"starting  block \", i)\n",
    "    ddf = pd.read_csv(os.path.join(BLOCK_PATH,block))\n",
    "    df = feature_eng(ddf)\n",
    "    persist_bcolz(i,df[allcols].values.astype(np.float32), 'data/processed_main')\n",
    "    del ddf\n",
    "    del df\n",
    "    print (\"completed block \", i)    \n",
    "da.flush()\n",
    "# save the string mapping dictionary    \n",
    "with open(\"data/cat_map.pkl\", \"wb\") as output_file:\n",
    "       pickle.dump(cat_map, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = bcolz.open(rootdir='data/processed_main', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171240269"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
