{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample, randint\n",
    "import os, datetime\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "import logging\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import  warnings,sklearn\n",
    "import pickle\n",
    "# Import the email modules we'll need\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from email.message import EmailMessage\n",
    "from pandas_ml import ConfusionMatrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam, Adadelta, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras import regularizers\n",
    "import random\n",
    "from keras_multi_input import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/pandas/io/feather_format.py:112: FutureWarning: `nthreads` argument is deprecated, pass `use_threads` instead\n",
      "  return feather.read_dataframe(path, nthreads=nthreads)\n"
     ]
    }
   ],
   "source": [
    "current_directory = '.'\n",
    "log_file = os.path.join(current_directory, 'data/wp.log')\n",
    "feather_file = os.path.join(current_directory, 'data/total_data_filled.feather')\n",
    "df = pd.read_feather(feather_file)\n",
    "df = df.set_index([ 'index', 'day'])\n",
    "# read in the prepared data set\n",
    "logger = logging.getLogger('wp')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "fh = logging.FileHandler(log_file)\n",
    "fh.setLevel(logging.INFO)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "# create formatter and add it to the handlers\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "ch.setFormatter(formatter)\n",
    "# add the handlers to the logger\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(ch)\n",
    "# date_fields = [\"temperatureMaxTime\", \"temperatureMinTime\", \"apparentTemperatureMinTime\",\n",
    "#                 \"apparentTemperatureHighTime\",\"sunsetTime\", \"uvIndexTime\"  ,\"sunriseTime\",\"temperatureHighTime\", \"temperatureLowTime\", \n",
    "#                  \"apparentTemperatureMaxTime\",\n",
    "#                  \"apparentTemperatureLowTime\"]\n",
    "\n",
    "# for date_field in date_fields:\n",
    "#     name = date_field.replace('Time', 'Hour')\n",
    "#     df[name] = df[date_field].apply(lambda x: x.hour)\n",
    "df = df.drop([ 'energy_count', \"temperatureMaxTime\", \"temperatureMinTime\", \"apparentTemperatureMinTime\",\n",
    "                \"apparentTemperatureHighTime\",\"sunsetTime\", \"uvIndexTime\"  ,\"sunriseTime\",\"temperatureHighTime\", \"temperatureLowTime\", \n",
    "                 \"apparentTemperatureMaxTime\",\n",
    "                 \"apparentTemperatureLowTime\"], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-24 13:14:36,895 - wp - INFO -                           LCLid  energy_sum stdorToU    Acorn Acorn_grouped  \\\n",
      "index     day                                                                 \n",
      "MAC000002 2012-10-12  MAC000002       7.098      Std  ACORN-A      Affluent   \n",
      "          2012-10-13  MAC000002      11.087      Std  ACORN-A      Affluent   \n",
      "          2012-10-14  MAC000002      13.223      Std  ACORN-A      Affluent   \n",
      "          2012-10-15  MAC000002      10.257      Std  ACORN-A      Affluent   \n",
      "          2012-10-16  MAC000002       9.769      Std  ACORN-A      Affluent   \n",
      "\n",
      "                      temperatureMax  windBearing               icon  \\\n",
      "index     day                                                          \n",
      "MAC000002 2012-10-12           11.53        252.0  partly-cloudy-day   \n",
      "          2012-10-13           12.32        300.0  partly-cloudy-day   \n",
      "          2012-10-14           13.03        220.0  partly-cloudy-day   \n",
      "          2012-10-15           14.74        226.0               wind   \n",
      "          2012-10-16           16.60        178.0  partly-cloudy-day   \n",
      "\n",
      "                      dewPoint  cloudCover             ...              \\\n",
      "index     day                                          ...               \n",
      "MAC000002 2012-10-12      6.15        0.29             ...               \n",
      "          2012-10-13      4.10        0.20             ...               \n",
      "          2012-10-14      6.39        0.31             ...               \n",
      "          2012-10-15      6.91        0.39             ...               \n",
      "          2012-10-16      9.87        0.42             ...               \n",
      "\n",
      "                      temperatureMinHour  apparentTemperatureMinHour  \\\n",
      "index     day                                                          \n",
      "MAC000002 2012-10-12                22.0                        22.0   \n",
      "          2012-10-13                 7.0                         6.0   \n",
      "          2012-10-14                 3.0                         4.0   \n",
      "          2012-10-15                21.0                         6.0   \n",
      "          2012-10-16                23.0                        23.0   \n",
      "\n",
      "                      apparentTemperatureHighHour sunsetHour  uvIndexHour  \\\n",
      "index     day                                                               \n",
      "MAC000002 2012-10-12                         14.0       17.0         12.0   \n",
      "          2012-10-13                         14.0       17.0         12.0   \n",
      "          2012-10-14                         14.0       17.0          9.0   \n",
      "          2012-10-15                         14.0       17.0          9.0   \n",
      "          2012-10-16                         13.0       17.0          9.0   \n",
      "\n",
      "                      sunriseHour  temperatureHighHour  temperatureLowHour  \\\n",
      "index     day                                                                \n",
      "MAC000002 2012-10-12          6.0                 14.0                 7.0   \n",
      "          2012-10-13          6.0                 14.0                 3.0   \n",
      "          2012-10-14          6.0                 14.0                 5.0   \n",
      "          2012-10-15          6.0                 14.0                23.0   \n",
      "          2012-10-16          6.0                 13.0                 7.0   \n",
      "\n",
      "                      apparentTemperatureMaxHour  apparentTemperatureLowHour  \n",
      "index     day                                                                 \n",
      "MAC000002 2012-10-12                        14.0                         6.0  \n",
      "          2012-10-13                        14.0                         4.0  \n",
      "          2012-10-14                        14.0                         6.0  \n",
      "          2012-10-15                        14.0                        23.0  \n",
      "          2012-10-16                        13.0                         7.0  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.drop([ 'energy_mean', 'energy_max', 'energy_std','energy_min', \n",
    "              'energy_skewness', 'energy_kurtosis', \n",
    "              'energy_median','energey_max_usage_hour'], \n",
    "              axis = 1)\n",
    "\n",
    "logger.info(df.head())\n",
    "\n",
    "validation_days = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-24 13:14:36,978 - wp - INFO - ['LCLid', 'Acorn', 'Acorn_grouped', 'icon', 'stdorToU', 'Type', 'day.of.week', 'precipType', 'summary', 'before_holiday', 'after_holiday', 'month', 'year']\n",
      "2018-10-24 13:14:44,419 - wp - INFO - [(5567, 50), (20, 10), (6, 3), (7, 4), (3, 2), (13, 7), (8, 4), (3, 2), (87, 44), (7, 4), (7, 4), (13, 7), (5, 3)]\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['LCLid','Acorn', 'Acorn_grouped', \"icon\", \"stdorToU\", \"Type\", \"day.of.week\", 'precipType',  'summary', 'before_holiday', 'after_holiday', 'month', 'year']\n",
    "non_categorical_columns =list(filter(lambda x: x not in categorical_columns, df.columns))\n",
    "\n",
    "label_column = 'energy_sum'\n",
    "logger.info(categorical_columns)\n",
    "\n",
    "for v in categorical_columns:\n",
    "    df[v] = df[v].astype('category').cat.as_ordered()\n",
    "for v in non_categorical_columns:\n",
    "    df[v] = df[v].astype('float32')\n",
    "cat_sz = [(c, len(df[c].cat.categories)+1) for c in categorical_columns]\n",
    "emb_szs = [(c, min(50, (c+1)//2)) for _,c in cat_sz]\n",
    "logger.info(emb_szs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-24 13:15:25,552 - wp - INFO - LCLid                            int16\n",
      "Acorn                             int8\n",
      "Acorn_grouped                     int8\n",
      "icon                              int8\n",
      "stdorToU                          int8\n",
      "Type                              int8\n",
      "day.of.week                       int8\n",
      "precipType                        int8\n",
      "summary                           int8\n",
      "before_holiday                    int8\n",
      "after_holiday                     int8\n",
      "month                             int8\n",
      "year                              int8\n",
      "temperatureMax                 float64\n",
      "windBearing                    float64\n",
      "dewPoint                       float64\n",
      "cloudCover                     float64\n",
      "windSpeed                      float64\n",
      "pressure                       float64\n",
      "apparentTemperatureHigh        float64\n",
      "visibility                     float64\n",
      "humidity                       float64\n",
      "apparentTemperatureLow         float64\n",
      "apparentTemperatureMax         float64\n",
      "uvIndex                        float64\n",
      "temperatureLow                 float64\n",
      "temperatureMin                 float64\n",
      "temperatureHigh                float64\n",
      "apparentTemperatureMin         float64\n",
      "moonPhase                      float64\n",
      "temperature_skewness           float64\n",
      "temperature_kurtosis           float64\n",
      "day_length                     float64\n",
      "temperatureMaxHour             float64\n",
      "temperatureMinHour             float64\n",
      "apparentTemperatureMinHour     float64\n",
      "apparentTemperatureHighHour    float64\n",
      "sunsetHour                     float64\n",
      "uvIndexHour                    float64\n",
      "sunriseHour                    float64\n",
      "temperatureHighHour            float64\n",
      "temperatureLowHour             float64\n",
      "apparentTemperatureMaxHour     float64\n",
      "apparentTemperatureLowHour     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df, y, nas, mapper = proc_df(df, y_fld=label_column,  do_scale=True)\n",
    "non_categorical_columns =list(filter(lambda x: x not in categorical_columns, df.columns))\n",
    "df = df[categorical_columns + non_categorical_columns ]\n",
    "logger.info(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-24 13:15:35,750 - wp - INFO -                       LCLid  Acorn  Acorn_grouped  icon  stdorToU  Type  \\\n",
      "index     day                                                             \n",
      "MAC000002 2012-10-12      1      2              4     4         1     8   \n",
      "          2012-10-13      1      2              4     4         1     8   \n",
      "          2012-10-14      1      2              4     4         1     8   \n",
      "          2012-10-15      1      2              4     6         1     8   \n",
      "          2012-10-16      1      2              4     4         1     8   \n",
      "\n",
      "                      day.of.week  precipType  summary  before_holiday  \\\n",
      "index     day                                                            \n",
      "MAC000002 2012-10-12            1           1       84               6   \n",
      "          2012-10-13            3           1       65               6   \n",
      "          2012-10-14            4           1       74               6   \n",
      "          2012-10-15            2           1       72               6   \n",
      "          2012-10-16            6           1       74               6   \n",
      "\n",
      "                                 ...              temperatureMinHour  \\\n",
      "index     day                    ...                                   \n",
      "MAC000002 2012-10-12             ...                        1.644255   \n",
      "          2012-10-13             ...                       -0.256139   \n",
      "          2012-10-14             ...                       -0.762910   \n",
      "          2012-10-15             ...                        1.517562   \n",
      "          2012-10-16             ...                        1.770948   \n",
      "\n",
      "                      apparentTemperatureMinHour  apparentTemperatureHighHour  \\\n",
      "index     day                                                                   \n",
      "MAC000002 2012-10-12                    1.771546                    -0.100368   \n",
      "          2012-10-13                   -0.349269                    -0.100368   \n",
      "          2012-10-14                   -0.614371                    -0.100368   \n",
      "          2012-10-15                   -0.349269                    -0.100368   \n",
      "          2012-10-16                    1.904097                    -0.546165   \n",
      "\n",
      "                      sunsetHour  uvIndexHour  sunriseHour  \\\n",
      "index     day                                                \n",
      "MAC000002 2012-10-12   -0.341907     0.767750     0.319169   \n",
      "          2012-10-13   -0.341907     0.767750     0.319169   \n",
      "          2012-10-14   -0.341907    -0.857823     0.319169   \n",
      "          2012-10-15   -0.341907    -0.857823     0.319169   \n",
      "          2012-10-16   -0.341907    -0.857823     0.319169   \n",
      "\n",
      "                      temperatureHighHour  temperatureLowHour  \\\n",
      "index     day                                                   \n",
      "MAC000002 2012-10-12            -0.088992            0.135291   \n",
      "          2012-10-13            -0.088992           -0.667536   \n",
      "          2012-10-14            -0.088992           -0.266122   \n",
      "          2012-10-15            -0.088992            3.346599   \n",
      "          2012-10-16            -0.569784            0.135291   \n",
      "\n",
      "                      apparentTemperatureMaxHour  apparentTemperatureLowHour  \n",
      "index     day                                                                 \n",
      "MAC000002 2012-10-12                    0.065707                   -0.154603  \n",
      "          2012-10-13                    0.065707                   -0.507284  \n",
      "          2012-10-14                    0.065707                   -0.154603  \n",
      "          2012-10-15                    0.065707                    2.843186  \n",
      "          2012-10-16                   -0.146046                    0.021738  \n",
      "\n",
      "[5 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "logger.info(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-24 13:15:37,417 - wp - INFO - Index(['LCLid', 'Acorn', 'Acorn_grouped', 'icon', 'stdorToU', 'Type',\n",
      "       'day.of.week', 'precipType', 'summary', 'before_holiday',\n",
      "       'after_holiday', 'month', 'year', 'temperatureMax', 'windBearing',\n",
      "       'dewPoint', 'cloudCover', 'windSpeed', 'pressure',\n",
      "       'apparentTemperatureHigh', 'visibility', 'humidity',\n",
      "       'apparentTemperatureLow', 'apparentTemperatureMax', 'uvIndex',\n",
      "       'temperatureLow', 'temperatureMin', 'temperatureHigh',\n",
      "       'apparentTemperatureMin', 'moonPhase', 'temperature_skewness',\n",
      "       'temperature_kurtosis', 'day_length', 'temperatureMaxHour',\n",
      "       'temperatureMinHour', 'apparentTemperatureMinHour',\n",
      "       'apparentTemperatureHighHour', 'sunsetHour', 'uvIndexHour',\n",
      "       'sunriseHour', 'temperatureHighHour', 'temperatureLowHour',\n",
      "       'apparentTemperatureMaxHour', 'apparentTemperatureLowHour'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "logger.info(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_date = max(df.index)[1]\n",
    "valid_start_day = max_date - timedelta(days=validation_days) \n",
    "\n",
    "train_idx = list(filter(lambda t: t[1] < valid_start_day, df.index))\n",
    "valid_idx = list(filter(lambda t: t[1] >= valid_start_day, df.index))\n",
    "max_y = max(y)*1.2\n",
    "y = pd.DataFrame(y, index = df.index, columns=['Value'])\n",
    "X_train = df.loc[train_idx]\n",
    "y_train = y.loc[train_idx].values.reshape(-1,1)\n",
    "X_valid = df.loc[valid_idx]\n",
    "y_valid = y.loc[valid_idx].values.reshape(-1,1)\n",
    "y_train = y_train/max_y\n",
    "y_valid = y_valid/max_y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-24 13:44:05,333 - wp - INFO - None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "year (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_91 (Embedding)        (None, 1, 3)         15          year[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 3)            0           embedding_91[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "continuouse (InputLayer)        (None, 31)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 34)           0           flatten_7[0][0]                  \n",
      "                                                                 continuouse[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 34)           136         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 64)           2240        batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 4)            260         dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            5           dense_16[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,656\n",
      "Trainable params: 2,588\n",
      "Non-trainable params: 68\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model setup\n",
    "batch_size=2000\n",
    "epochs=20\n",
    "lr = 0.001\n",
    "l2_reg= 0.0\n",
    "\n",
    "cat_input = [Input(shape=(1,), dtype='int32', name=c) for c in categorical_columns]\n",
    "all_layers = []\n",
    "for i in range(len(cat_input)):\n",
    "    emb = layers.Embedding(emb_szs[i][0], emb_szs[i][1])(cat_input[i])\n",
    "flat = layers.Flatten()(emb)\n",
    "all_layers.append(flat)\n",
    "\n",
    "contInput = Input(shape=(len(non_categorical_columns),), dtype='float32', name='continuouse')\n",
    "all_layers.append(contInput)\n",
    "lay = layers.concatenate(all_layers, axis =-1)\n",
    "lay = BatchNormalization()(lay)\n",
    "lay = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l2_reg))(lay)\n",
    "lay = Dense(4, activation='relu', kernel_regularizer=regularizers.l2(l2_reg))(lay)\n",
    "answer = layers.Dense(1, activation='sigmoid')(lay)\n",
    "inputs_all = cat_input\n",
    "inputs_all.append(contInput)\n",
    "model = Model(inputs_all, answer)\n",
    "logger.info(model.summary())\n",
    "adam = Adam(lr=lr)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam,metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6904877 samples, validate on 152624 samples\n",
      "Epoch 1/20\n",
      " - 25s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00001: val_loss did not improve from inf\n",
      "Epoch 2/20\n",
      " - 24s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00002: val_loss did not improve from inf\n",
      "Epoch 3/20\n",
      " - 24s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00003: val_loss did not improve from inf\n",
      "Epoch 4/20\n",
      " - 24s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00004: val_loss did not improve from inf\n",
      "Epoch 5/20\n",
      " - 24s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00005: val_loss did not improve from inf\n",
      "Epoch 6/20\n",
      " - 24s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00006: val_loss did not improve from inf\n",
      "Epoch 7/20\n",
      " - 24s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00007: val_loss did not improve from inf\n",
      "Epoch 8/20\n",
      " - 24s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00008: val_loss did not improve from inf\n",
      "Epoch 9/20\n",
      " - 24s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00009: val_loss did not improve from inf\n",
      "Epoch 10/20\n",
      " - 24s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00010: val_loss did not improve from inf\n",
      "Epoch 11/20\n",
      " - 24s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00011: val_loss did not improve from inf\n",
      "Epoch 12/20\n",
      " - 24s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00012: val_loss did not improve from inf\n",
      "Epoch 13/20\n",
      " - 24s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00013: val_loss did not improve from inf\n",
      "Epoch 14/20\n",
      " - 24s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00014: val_loss did not improve from inf\n",
      "Epoch 15/20\n",
      " - 24s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00015: val_loss did not improve from inf\n",
      "Epoch 16/20\n",
      " - 24s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00016: val_loss did not improve from inf\n",
      "Epoch 17/20\n",
      " - 24s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00017: val_loss did not improve from inf\n",
      "Epoch 18/20\n",
      " - 24s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00018: val_loss did not improve from inf\n",
      "Epoch 19/20\n",
      " - 24s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00019: val_loss did not improve from inf\n",
      "Epoch 20/20\n",
      " - 24s - loss: nan - mean_squared_error: nan - mean_absolute_error: nan - val_loss: nan - val_mean_squared_error: nan - val_mean_absolute_error: nan\n",
      "\n",
      "Epoch 00020: val_loss did not improve from inf\n"
     ]
    }
   ],
   "source": [
    "#fit data\n",
    "batch_size = 20000\n",
    "epochs=20\n",
    "name = './data/separate_LcLid.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=name, verbose=2, save_best_only=True)\n",
    "train_values = {c:X_train[c] for c in categorical_columns}\n",
    "train_values['continuouse'] = X_train[non_categorical_columns]\n",
    "\n",
    "val_values = {c:X_valid[c] for c in categorical_columns}\n",
    "val_values['continuouse'] = X_valid[non_categorical_columns]\n",
    "\n",
    "history = model.fit(train_values, y_train, epochs=epochs, batch_size = batch_size,\n",
    "                             validation_data=(val_values, y_valid), \n",
    "                             verbose=2, shuffle=True,\n",
    "                             #validation_split=0.2,\n",
    "                             callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(history.history['loss'], label='train')\n",
    "ax.plot(history.history['val_loss'], label='test')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01778648]\n",
      " [0.02778229]\n",
      " [0.03313477]\n",
      " [0.02570244]\n",
      " [0.02447959]\n",
      " [0.02727611]\n",
      " [0.02694033]\n",
      " [0.02112677]\n",
      " [0.04354655]\n",
      " [0.06136811]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
